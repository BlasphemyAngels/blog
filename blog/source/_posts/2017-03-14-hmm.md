---
layout: post
title: "时间序列分析之隐马尔科夫模型"
date: 2017-03-14
categories:
  - ML
tags: 
 - 时间序列
 - hmm
 - 概率图
---


## 正文

HMM曾经统治过语音识别领域，虽然它现在已经在一定程度上被RNN取代，但是其思想还是值得理解的。而且其在很多领域还有广泛的应用。

### 预习阅读

[图模型](https://blasphemyangels.github.io/2017/03/bayes/)

### 条件概率的贝叶斯模型

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(AB|C)=P(A|BC)P(B|C)" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(A|BC)=\frac{P(AB|C)}{P(B|C)}=\frac{P(B|AC)P(A|C)}{P(B|C)}" style="border:none;">

<!--more-->

### 引子

首先从一个例子开始。俗话说，人心不可测，而妹子的心更不可测。现在想这样一个模型。如下图，有两个状态，一个是妹子的心情X，和妹子的心情的外在表现(如摔东西，哭等)Y，那么如何通过Y推测X呢？

![hmmgirl](https://github.com/BlasphemyAngels/MarkDownPhotos/blob/master/hmmgirl.png?raw=true)


由贝叶斯公司可以得到：

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X|Y) = \frac{P(Y|X)P(X)}{P(Y)}" style="border:none;">

其中P(Y\|X)，P(X)，P(Y)可以通过统计得到，那么这就可以得到一个能够通过妹子的外在表现推测妹子心情的模型。

### HMM

将上面的模型，扩展一下，想一想，妹子的心情是多种多样的，而且可以相互变换，于是得到下面的模型。

![hmm3](https://github.com/BlasphemyAngels/MarkDownPhotos/blob/master/hmm3.png?raw=true)

首先，Y1，Y2，Y3，这些外在特征是可以通过观测数据得到的。

首先想一想，怎么得到<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X_t|Y_{1:t-1})" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X_t|Y_{1:t-1})=\sum_{X_{t-1}}P(X_t, X_{t-1}|Y_{1:t-1})" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= =\sum_{X_{t-1}}P(X_t|X_{t-1}, Y_{1:t-1})P(X_{t-1}|Y_{1:t-1})" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= =\sum_{X_{t-1}}P(X_t|X_{t-1})P(X_{t-1}|Y_{1:t-1})" style="border:none;">


现在再来考虑<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X_t|Y_t)" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X_t|Y_t)=P(X_t|Y_{1:t-1}, Y_t)=\frac{P(Y_t|X_t, Y_{1:t-1})P(X_t|Y_{1:t-1})}{P(Y_t|Y_{1:t-1})}" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X_t|Y_t)=P(X_t|Y_{1:t-1}, Y_t)=\frac{P(Y_t|X_t, Y_{1:t-1})P(X_t|Y_{1:t-1})}{\sum_{X_t}P(Y_t|X_t, Y_{1:t-1})P(X_t|Y_{1:t-1})}" style="border:none;">

由图模型假设没有边相连的变量是相互独立的。

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X_t|Y_t)=P(X_t|Y_{1:t-1}, Y_t)=\frac{P(Y_t|X_t)P(X_t|Y_{1:t-1})}{\sum_{X_t}P(Y_t|X_t)P(X_t|Y_{1:t-1})}" style="border:none;">

再将带入<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X_t|Y_{1:t-1})" style="border:none;">可得到一个递归方程，根据这个方程进行动态规划就能求得<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(X_t|Y_t)" style="border:none;">


### Time Machine

看下面一个模型：

![hmm4](https://github.com/BlasphemyAngels/MarkDownPhotos/blob/master/hmm4.png?raw=true)

模型中事件序列x1,x2,...,xt存在相关性，如图中x3是x1和x2的线性组合，其实就是加权和。这种模型称为auto regressive model。模型中的参数是可学的，也可以称可fit的。这是最简单的时间序列模型。

### RNN初涉

RNN是一种神经网络结构，它在一些方面能够替代HMM，且效果更好。LSTM是一种特殊的 RNN,把sigmod函数变成了另一系列的东西。RNN能并行运算，所以它能处理大的数据，RNN存在梯度消失问题，LSTM就是为了解决这个问题，这里只是粗略提及一点，后面会详细介绍。

### 总结

HMM是一个思想，没有统一的形式，在不同的问题中不一样，要看实际问题仔细分析，然后借鉴其思想解决问题。

<br>

转载请注明:[Artemis的博客]([https://BlasphemyAngels.github.io)--> [点此看原文 ](https://blasphemyangels.github.io/2017/03/hmm/)

