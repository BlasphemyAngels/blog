---
title: Image-Text matching papper
date: 2017-05-22 16:31:57
categories:
  - papper
tags:
  - Image-Text matching
  - papper
---


&ensp;&ensp;&ensp;<font color=#0099ff size=5>Image-Text matching</font>是与多个方向相关的一个任务，下面就展示一下我自己收集的一些论文。

<!--more-->

## 正文

### 2017

* Image Retrieval

  * Under Review CVPR&ensp;<font color=red>A类</font> 2017
    * [Asymmetrically Weighted CCA And Hierarchical Kernel Sentence Embedding For Image & Text Retrieval<br/>](https://arxiv.org/abs/1511.06267)引用量：1

  * in submission for TPAMI
    * [Learning Two-Branch Neural Networks for Image-Text Matching Tasks<br/>](https://arxiv.org/abs/1704.03470)引用量：0

  * CVPR&ensp;<font color=red>A类</font>
    * [Generating Holistic 3D Scene Abstractions for Text-based Image Retrieval<br/>](https://arxiv.org/abs/1611.09392)引用量：0

* VQA

  * arXiv
    * [Hierarchical Recurrent Attention Network for Response Generation<br/>](https://arxiv.org/abs/1701.07149)引用量：0

* Image Caption & Image Annonation

  * arXiv
    *  [Learning Semantics for Image Annotation<br/>](https://arxiv.org/abs/1705.05102y)引用量：0

* RL

  * Under Review CVPR&ensp;<font color=red>A类</font>
    
    * [Self-critical Sequence Training for Image Captioning<br/>](https://arxiv.org/abs/1612.00563)引用量：3

    * [Improved Image Captioning via Policy Gradient optimization of SPIDEr<br/>](https://arxiv.org/abs/1612.00370)引用量：4

### 2016

* 基于检索

  * CVPR&ensp;<font color=red>A类</font>

    * [Learning Deep Structure-Preserving Image-Text Embeddings<br/>](https://arxiv.org/abs/1511.06078)引用量：19

    * [Aggregating Image and Text Quantized Correlated Components<br/>](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Tran_Aggregating_Image_and_CVPR_2016_paper.pdf) 引用量：1

    * [DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations<br/>](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf) 引用量：10

  * ECCV&ensp;<font color=red>B类</font>

    * [CNN Image Retrieval Learns from BoW: Unsupervised Fine-Tuning with Hard Examples<br/>](https://arxiv.org/abs/1604.02426)引用量：16

    * [Kernel-Based Supervised Discrete Hashing for Image Retrieval<br/>](https://www.cise.ufl.edu/~zizhao/paper_list/eccv2016.pdf)引用量：1

    * [Deep Image Retrieval: Learning global representations for image search<br/>](https://arxiv.org/abs/1604.01325)引用量：12

  * arXiv

    * [Linking Image and Text with 2-Way Nets<br/>](https://arxiv.org/abs/1608.07973)引用量：1

* Multimodal 

  * CVPR&ensp;<font color=red>A类</font>

    * [MDL-CW: A Multimodal Deep Learning Framework with CrossWeights<br/>](http://z-yt.net/tmp/cvpr2016/content/papers/8851c601.p) 引用量：0

* 图像生成

  * ICML&ensp;<font color=red>A类</font>

    * [Generative Adversarial Text to Image Synthesis<br/>](https://arxiv.org/abs/1605.05396)引用量：46

* Visual Grounding

  * ECCV&ensp;<font color=red>B类</font>

    * [Modeling Context in Referring Expressions<br/>](https://arxiv.org/abs/1608.00272)引用量：8

    * [Modeling Context Between Objects for Referring Expression Understanding<br/>](https://arxiv.org/abs/1608.00525)引用量：3

    * [Structured Matching for Phrase Localization<br/>](https://link.springer.com/chapter/10.1007%2F978-3-319-46484-8_42) 引用量：2

  * CVPR&ensp;<font color=red>A类</font>

    * [Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes<br/>](https://arxiv.org/abs/1511.07067)引用量：6

* Image Caption & Image Annonation

  * ICLR

    * [Order-Embeddings of Images and Language<br/>](https://arxiv.org/abs/1511.06361)引用量：31 <br/>在视觉-语义的层级上对其做偏序结构处理

    * [Trainable performance upper bounds for image and video captioning<br/>](https://arxiv.org/abs/1511.04590v1)引用量：2

    * [Generating Images from Captions with Attention<br/>](https://arxiv.org/abs/1511.02793)引用量：25

  * CVPR&ensp;<font color=red>A类</font>

    * [What value do explicit high level concepts have in vision to language problems?<br/>](https://arxiv.org/abs/1506.01144)引用量：8

    * [Image Captioning with Semantic Attention<br/>](https://arxiv.org/abs/1603.03925)引用量：36

    * [Learning Deep Representations of Fine-grained Visual Descriptions<br/>](https://arxiv.org/abs/1605.05395)引用量：16

    * [Learning to Read Chest X-Rays: Recurrent Neural Cascade Model for Automated Image Annotation<br/>](https://arxiv.org/abs/1603.08486)引用量：4

  * ECCV&ensp;<font color=red>B类</font>

    * [SPICE: Semantic Propositional Image Caption Evaluation<br/>](https://arxiv.org/abs/1607.08822)引用量：12

    * [RNN Fisher Vectors for Action Recognition and Image Annotation<br/>](https://arxiv.org/abs/1512.03958v1)引用量：5

    * [Leveraging Visual Question Answering for Image-Caption Ranking<br/>](https://arxiv.org/abs/1605.01379)引用量：4

  * BMVC&ensp;<font color=red>C类</font>

    * [Oracle performance for visual captioning<br/>](https://arxiv.org/abs/1511.04590)引用量：2

  * Meeting of the Association for Computational Linguistics

    * [Generating Natural Questions About an Image<br/>](https://arxiv.org/abs/1603.06059)引用量：1

  * arXiv

    * [Image Caption Generation with Text-Conditional Semantic Attention<br/>](https://arxiv.org/abs/1606.04621v2)引用量：1

    * [Boosting Image Captioning with Attributes<br/>](https://arxiv.org/abs/1611.01646)引用量：4

    * [Knowing When to Look: Adaptive Attention via A Visual Sentinel for Image Captioning<br/>](https://arxiv.org/abs/1612.01887)引用量：3

* 文本相似

  * HICSS

    * [Text-Based Document Similarity Matching Using Sdtext<br/>](http://people.cs.georgetown.edu/~clay/research/pubs/shields-hicss-2016.pdf) 引用量：0

* Generate Model

  * arXiv

    * [Learning to Generate with Memory<br/>](https://arxiv.org/abs/1602.07416)引用量：5

* Multi-task learning

  * SigKdd&ensp;<font color=red>A类</font>

    * [Multi-Task Feature Interaction Learning<br/>](http://www.kdd.org/kdd2016/papers/files/rpp0423-linA.pdf)引用量：0

* VQA

  * ECCV&ensp;<font color=red>B类</font>

    * [Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering<br/>](https://arxiv.org/abs/1511.05234)引用量：39

    * [Revisiting Visual Question Answering Baselines<br/>](https://arxiv.org/abs/1606.08390)引用量：14

    * [Learning Models for Actions and Person-Object Interactions with Transfer to Question Answering](https://arxiv.org/abs/1604.04808)

    * [Leveraging Visual Question Answering for Image-Caption Ranking<br/>](https://arxiv.org/abs/1605.01379)引用量：4

  * CVPR&ensp;<font color=red>A类</font>

    * [Deep Supervised Hashing for Fast Image Retrieval<br/>](http://z-yt.net/tmp/cvpr2016/content/papers/8851c064.pdf) 引用量：5

    * [Visual7W: Grounded Question Answering in Images<br/>](https://arxiv.org/abs/1511.03416)引用量：34 <br/> 李飞飞老师的文章，这篇提出了一个新的数据集Visual7W

    * [Where To Look: Focus Regions for Visual Question Answering<br/>](https://arxiv.org/abs/1511.07394)引用量：29 <br/>加入attention机制的一篇文章

    * [Ask Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources<br/>](https://arxiv.org/abs/1511.06973)引用量：12 <br/> 沈春华老师的文章，这篇加入了外接知识库

    * [Answer-Type Prediction for Visual Question Answering<br/>](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kafle_Answer-Type_Prediction_for_CVPR_2016_paper.pdf) 引用量：7

    * [Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction<br/>](https://arxiv.org/abs/1511.05756)
    
    * [Stacked Attention Networks for Image QuestionAnswering<br/>](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_Stacked_Attention_Networks_CVPR_2016_paper.pdf) 采用多次关注聚焦的方式来处理定位问题关注点

    * [Neural Module Networks](https://arxiv.org/abs/1511.02799) <br/>根据问题不同动态组合网络

    * [MovieQA: Understanding Stories in Movies through Question-Answering](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Tapaswi_MovieQA_Understanding_Stories_CVPR_2016_paper.pdf)

    * [Yin and Yang: Balancing and Answering Binary Visual Questions](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhang_Yin_and_Yang_CVPR_2016_paper.pdf)

  * arXiv

    * [Visual Question Answering: Datasets, Algorithms, and Future Challenges<br/>](https://arxiv.org/abs/1610.01465) 综述性文章

    * [Visual Question Answering: A Survey of Methods and Datasets<br/>](https://arxiv.org/abs/1607.05910) 综述性文章

    * [Image Captioning and Visual Question Answering Based on Attributes and External Knowledge<br/>](https://arxiv.org/abs/1603.02814) 沈春华老师的文章，提取高层次语义概念的图像特征

  * AAAI&ensp;<font color=red>A类</font>

    * [Learning to Answer Questions From Image Using Convolutional Neural Network<br/>](https://arxiv.org/abs/1506.00333)

  * NIPS&ensp;<font color=red>A类</font>

    * [Hierarchical Question-Image Co-Attention for Visual Question Answering<br/>](https://arxiv.org/abs/1606.00061) 采用图像attention问题，再用问题attention图像

  * PMLR

    * [Dynamic Memory Networks for Visual and Textual Question Answering<br/>](https://arxiv.org/abs/1603.01417)

* 图像匹配

  * ECCV&ensp;<font color=red>B类</font>

    * [Matching Handwritten Document Images<br/>](https://arxiv.org/abs/1605.05923v1)引用量：3

    * [Learning Image Matching by Simply Watching Video<br/>](https://arxiv.org/abs/1603.06041v1)引用量：3

* Cross-Modal Retrieval
  
  * SigKdd&ensp;<font color=red>A类</font>

    * [Deep Visual-Semantic Hashing for Cross-Modal Retrieval<br/>](http://www.kdd.org/kdd2016/papers/files/rpp0086-caoA.pdf)引用量：6

  * ICMR&ensp;<font color=red>B类</font>

    * [Correlation Autoencoder Hashing for Supervised Cross-Modal Search<br/>](http://dl.acm.org/citation.cfm?doid=2911996.2912000)引用量：2

  * arXiv

    * [Correlation Hashing Network for Efficient Cross-Modal Retrieval<br/>](https://arxiv.org/abs/1602.06697)引用量：3

* RL

  * ICLR

    * [Sequence Level Training with Recurrent Neural Networks<br/>](https://arxiv.org/abs/1511.06732)引用量：56

### 2015

* 基于检索

  * ICCV&ensp;<font color=red>A类</font>

    * [Multimodal Convolutional Neural Networks for Matching Image and Sentence<br/>](https://arxiv.org/abs/1504.06063)引用量：31

    * [LEWIS: Latent Embeddings for Word Images and their Semantics<br/>](https://arxiv.org/abs/1509.06243)引用量：1

  * CVPR&ensp;<font color=red>A类</font>

    * [Associating Neural Word Embeddings with Deep Image Representations using Fisher Vectors<br/>](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Klein_Associating_Neural_Word_2015_CVPR_paper.pdf) 引用量：21

    * [Deep correlation for matching images and text<br/>](http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_012_ext.pdf) 引用量：31 <br/>采用 canonical correlation analysis 作为目标函数，但这种目标函数不容易求导

  * arXiv

    * [Deep Learning Applied to Image and Text Matching<br/>](https://arxiv.org/abs/1601.03478)引用量：0 <br/>类似综述类的一类文章，文章很长，但是在后半段作者阐述了自己的工作。总的来说，前面的综述部分还可以。

* 基于生成

  * ICLR

    * [Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)<br/>](https://arxiv.org/abs/1412.6632v5)引用量：181

  * CVPR&ensp;<font color=red>A类</font>

    * [Show and Tell: A Neural Image Caption Generator<br/>](https://arxiv.org/abs/1411.4555)作者：Bengio 引用量：583


* Image Matching

  * ICCV&ensp;<font color=red>A类</font>

    * [Multi-Image Matching via Fast Alternating Minimization<br/>](https://arxiv.org/abs/1505.04845)引用量：7

* Image Caption & Image Annonation

  * CVPR&ensp;<font color=red>A类</font>

    * [Deep Visual-Semantic Alignments for Generating Image Descriptions<br/>](https://arxiv.org/abs/1412.2306)引用量：535

    * [Learning a Recurrent Visual Representation for Image Caption Generation<br/>](https://arxiv.org/abs/1411.5654)引用量：76

  * ICML&ensp;<font color=red>A类</font>

    * [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention<br/>](https://arxiv.org/abs/1502.03044)引用量：537

    * [Phrase-based Image Captioning<br/>](https://arxiv.org/abs/1502.03671)引用量：26

  * ICCV&ensp;<font color=red>A类</font>

    * [Guiding Long-Short Term Memory for Image Caption Generation<br/>](https://arxiv.org/abs/1509.04942)引用量：1

* 图像语义分割

  * CVPR&ensp;<font color=red>A类</font>

    * [Fully Convolutional Networks for Semantic Segmentation<br/>](https://arxiv.org/abs/1411.4038)引用量：902

* Multi-task learning
  
  * CVPR&ensp;<font color=red>A类</font>
    
    * [Curriculum Learning of Multiple Tasks](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Pentina_Curriculum_Learning_of_2015_CVPR_paper.pdf)

* VQA

  * ICCV&ensp;<font color=red>A类</font>

    * [Ask Your Neurons: A Neural-based Approach to Answering Questions about Images<br/>](https://arxiv.org/abs/1505.01121)

    * [VQA: Visual Question Answering<br/>](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Antol_VQA_Visual_Question_ICCV_2015_paper.pdf)
        提出了目前最大的数据集mscocoQA 网页：http://www.visualqa.org/

    * [Visual Madlibs: Fill in the blank Image Generation and Question Answering](https://arxiv.org/abs/1506.00278)

  * NIPS&ensp;<font color=red>A类</font>

    * [Exploring Models and Data for Image Question Answering<br/>](https://arxiv.org/abs/1505.02074)

  * CVPR&ensp;<font color=red>A类</font>

    * [Don’t Just Listen, Use Your Imagination: Leveraging Visual Common Sense for Non-Visual Tasks](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Lin_Dont_Just_Listen_2015_CVPR_paper.pdf)

    * [VisKE: Visual Knowledge Extraction and Question Answering by Visual Verification of Relation Phrases](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Sadeghi_VisKE_Visual_Knowledge_2015_CVPR_paper.pdf)

### 2014

* 基于检索

  * NIPS&ensp;<font color=red>A类</font>

    * [Deep Fragment Embeddings for Bidirectional Image Sentence Mapping<br/>](https://arxiv.org/abs/1406.5679)引用量:161

    * [Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models<br/>](https://arxiv.org/abs/1411.2539)引用量：202

* 基于生成

  * CVPR&ensp;<font color=red>A类</font>

    * [From Captions to Visual Concepts and Back<br/>](https://arxiv.org/abs/1411.4952v3)引用量:180

* Visual Grounding

* Multimodal Representations

  * TPAMI&ensp;<font color=red>A类</font>

    * [Spherical and Hyperbolic Embeddings of Data<br/>](https://core.ac.uk/download/pdf/19967857.pdf)
  * ICML

    * [Multimodal neural language models](http://machinelearning.wustl.edu/mlpapers/paper_files/icml2014c2_kiros14.pdf)
        log-bilinear nerual language models

  * arXiv

    * [Explain images with multi-modal recurrent neural networks](http://www.cs.cmu.edu/~ark/EMNLP-2015/proceedings/VL/pdf/VL04.pdf)
        RNN

* Image Caption & Image Annonation

  * Meeting of the Association for Computational Linguistics

    * [Comparing Automatic Evaluation Measures for Image Description<br/>](http://acl2014.org/acl2014/P14-2/xml/P14-2074.xhtml)引用量：42 论文比较了几种常见的图像描述问题的评价方法

  * Computer Science

    * [Explain Images with Multimodal Recurrent Neural Networks<br/>](https://arxiv.org/abs/1410.1090?context=cs.CV)引用量：94

  * ICLR

    * [Deep Convolutional Ranking for Multilabel Image Annotation<br/>](https://arxiv.org/abs/1312.4894)引用量：71

  * ECCV
  
    * [Improving Image-Sentence Embeddings Using Large Weakly Annotated Photo Collections](http://slazebni.cs.illinois.edu/publications/yunchao_eccv14_sentence.pdf)
        normalized CCA

  * TACL

    * [Grounded compositional semantics for findingand describing images with sentences](http://www.cl.uni-heidelberg.de/courses/ws14/deepl/SocherETAL14.pdf)
        dependency tree recursive networks

  * ACL 2014 Workshop on Semantic Parsing

    * [A deeparchitecture for semantic parsing]()
        proposed a two-step embedding and generation procedure for semantic parsing.
* VQA

  * NIPS&ensp;<font color=red>A类</font>

    * [A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input<br/>](https://arxiv.org/abs/1410.0210v2)

* 图像语义分割

  * CVPR&ensp;<font color=red>A类</font>

    * [Rich feature hierarchies for accurate object detection and semantic segmentation Tech report (v5)<br/>](https://arxiv.org/abs/1311.2524)引用量：1969

### 2013 or before

* Image Retrieval

  * TPAMI&ensp;<font color=red>A类</font>

    * 2007--[Supervised Learning of Semantic Classes for Image Annotation and Retrieval<br/>](https://www.cs.swarthmore.edu/~turnbull/cs97/f09/paper/pami07-semantics.pdf) 引用量：980

* Multimodal Learning

  * NIPS&ensp;<font color=red>A类</font>

    * 2012--[Multimodal Learning with Deep Boltzmann Machines<br/>](http://datascienceassn.org/sites/default/files/Multimodal%20Learning%20with%20Deep%20Boltzmann%20Machines.pdf) 引用量：362 
    
  * ICML
    
    * [Mul-timodal deep learning](http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf)
        autoencoders
  * ICCV
  
    * 2011--[Learning cross-modality similarity formultinomial data](http://people.eecs.berkeley.edu/~trevor/iccv11-mm.pdf)
        topic models


### kernel CCA normalized CCA
