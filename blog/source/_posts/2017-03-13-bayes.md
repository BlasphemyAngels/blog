---
layout: post
title: "从贝叶斯到图模型"
date: 2017-03-12
categories:
  - ML
tags: 
  - bayes
  - 概率图模型
---

## 正文

### 贝叶斯公式

我们将基本事件空间B分割成n个互斥的的事件空间Bi，那么事件A的概率可以表示为:<br/>

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(A)=\sum_{i=1}^{n}P(AB_i)" style="border:none;">

考虑乘法公式:<br/>

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(B_i|A)=\frac{P(AB_i)}{P(A)}" style="border:none;">

可得:<br/>

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(A)=\sum_{i=1}^{n}P(A)P(B_i|A)" style="border:none;">

这就是全概率公式。<br/>

再由条件概率定义:

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(B_i|A)=\frac{P(AB_i)}{P(A)}=\frac{P(A|B_i)P(B_i)}{P(A)}=\frac{P(A|B_i)P(B_i)}{\sum_{i=1}^{n}P(A|B_i)P(B_i)}" style="border:none;">

这就是著名的贝叶斯定理。

<!--more-->

### 经典问题

#### 生病问题

加入一种病的患病率是万分之一，医院对这种病的检测准确率是99%，那么你去检测，医生告诉你检测呈阳性，那么你由多大几率真正患病？

设D=1代表患病，D=0代表不患病，C=0代表检测呈隐性，C=1代表检测呈阳性。

那么由题意可知:

P(D=1)=0.0001

P(C=1\|D=1)=0.99

P(C=0\|D=0)=0.99

则:

P(C=0\|D=1)=1-P(C=1\|D=1)=0.01

P(C=1\|D=0)=1-P(C=0\|D=0)=0.01

所以由贝叶斯公式:


<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(D=1|C=1)=\frac{P(C=1|D=1)P(D=1)}{\sum_{i=0}^{1}P(C=i|D=i)(P(D=i)}=0.0098" style="border:none;">

#### 奖品问题

有三扇门，只有一扇门后面有大奖，参与者可以选择一扇门，然后主持人从余下的两扇门中选择一扇没有奖品的打开，然后再问参与者是否换一扇门。请从数学的角度说明换好还是不换好。

设H=i(i=1,2,3)代表奖品在第i门后，D=i(i=1,2,3)代表主持人打开第i扇门。

不失一般性，不妨设用户打开第一扇门，则：

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(H=1)=P(H=2)=P(H=3)=\frac{1}{3}" style="border:none;">

P(D=2\|H=1)=P(D=3\|H=1)=0.5

P(D=2\|H=2)=0

P(D=3\|H=2)=1

P(D=2\|H=3)=1

P(D=3\|H=3)=0

由全概率公式：

<img src="http://chart.googleapis.com/chart?cht=tx&chl=P(D=3)=P(D=3|H=1)P(H=1)+P(D=3|H=2)P(H=2)+P(D=3|H=3)P(H=3)=\frac{1}{2}" style="border:none;">

不妨设主持人打开第三扇门，则由贝叶斯公式：

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(H=1|D=3)=\frac{P(D=3|H=1)P(H=1)}{P(D=3)}=\frac{1}{3}" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(H=2|D=3)=\frac{P(D=3|H=2)P(H=2)}{P(D=3)}=\frac{2}{3}" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(H=3|D=3)=\frac{P(D=3|H=3)P(H=3)}{P(D=3)}=0" style="border:none;">

所以换得大奖的几率大。

### 贝叶斯决策

经过贝叶斯计算出的概率称为后验概率，怎样根据后验概率来决策呢？

#### 风险

事件在状态wi可能有很多种动作，那么每一种动作所造成的代价称为风险。用风险函数<img src="http://chart.googleapis.com/chart?cht=tx&chl= \lambda(a_j,w_i)" style="border:none;">代表状态wi做出动作aj所造成的代价，即风险。

动作有很多种，比如在分类问题中，动作可能代表分到某一类去，而代价就是损失函数。

#### 经验损失最小化

前面计算得到的后验概率P(wi\|A)代表在一些条件下处于状态wi的概率，那么用它乘以损失函数:

<img src="http://chart.googleapis.com/chart?cht=tx&chl= R(w_i,a_j)=\sum_{j=1}^{c}\lambda(w_i,a_j)P(w_i|A)" style="border:none;">

这就是平均风险，也称为经验风险，找到使它最小化的动作的过程称为经验风险最小化。然后就可以进行决策。即使经验风险达到最小化的动作就是决策结果。

实际中，贝叶斯较难进行经验损失最小化，不过贝叶斯决策理论倒是为我们提供了一个与其他分类器做对比的评价依据，也就是说贝叶斯决策很多情况下是作为对比对象而存在的。


### 图模型之有向图

#### 背景

一般来说在用概率模型时，如果拥有了联合概率密度就相当于拥有了上帝视角，可以得到任何想要的东西，但是需要的耗费是指数级的，比如一共有d个变量，每个变量有0和1两个取值，那么就得维护一个2^d的概率表，以备查阅。这样一来耗费太大。基于这个问题的解决，人们提出忽略变量之间的依赖关系，只关心变量之间的核心依赖关系，即定义一个有向无环图，只需记录这些核心关系即可，这样就得到了图模型的有向图方法。

#### 有向无环图

有向无环图，Directed probabilistic graphical models(DAG)，是指图的结点间是有向边，而且整个图没有环，如下图：

![directgraph](https://github.com/BlasphemyAngels/MarkDownPhotos/blob/master/directgraph.png?raw=true)

图中没有线相连的结点是被假设没有关系的。结点跟它的祖先也是相互独立的，换句话说，结点只跟与它相连的直系父节点有关系。这个假设是根据实际场景的，每个人对它的定义和理解也是不同的。

那么:

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(B,E,A,R,C)=P(B,E,A,R)P(C|B,E,A,R)=P(B,E,A)P(R|B,E,A)P(C|B,E,A,R)" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= =P(B,E)P(A|B,E)P(R|B,E,A)P(C|B,E,A,R)=P(B)P(E|B)P(A|B,E)P(R|B,E,A)P(C|B,E,A,R)" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= =P(B)P(E)P(A|B,E)P(R|E)P(C|A)" style="border:none;">

这就告诉了我们，如果我们有n个变量xi那么这些变量的联合分布律是:

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(x_{1:n})=P(x_1,x_2,...,x_n)=\prod_{i=1}^{n}P(x_i|parents(x_i))" style="border:none;">

#### 怎么计算？

假设A有两个取值0和1，那么先求A的分布律：

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(A)=\sum_B\sum_E\sum_C\sum_RP(B,E,A,R,C)" style="border:none;">

如何计算上面的式子？最简单的方法是四重for循环，但是这样的话时间复杂度太大。那么怎么办呢？想想算法中的动态规划，这里叫做消元。变换求和次序得:

<img src="http://chart.googleapis.com/chart?cht=tx&chl= P(A)=\sum_B\sum_E\sum_C\sum_RP(B)P(E)P(A|B,E)P(R|E)P(C|A)" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= =\sum_B\sum_E\sum_CP(B)P(E)P(A|B,E)P(C|A)\sum_RP(R|E)" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= =\sum_B\sum_E\sum_CP(B)P(E)P(A|B,E)P(C|A)" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= =\sum_B\sum_EP(B)P(E)P(A|B,E)\sum_CP(C|A)" style="border:none;">

<img src="http://chart.googleapis.com/chart?cht=tx&chl= =\sum_B\sum_EP(B)P(E)P(A|B,E)" style="border:none;">

其中最后两步的变换是由于概率的归一性：

<img src="http://chart.googleapis.com/chart?cht=tx&chl= \sum_RP(R|E)=\sum_CP(C|A)=1" style="border:none;">

这里动态规划的思想是通过移动求和次序，消去变量，减少了重复计算。由四重循环变为了两重循环，大大减少了计算量。

#### Naïve Bayes

最后再讲一下有向概率图的一个特殊情况Naïve Bayes

Naïve Bayes是指下面这种有向概率图:

![naivebayes](https://github.com/BlasphemyAngels/MarkDownPhotos/blob/master/naivebayes.png?raw=true)

上图显示一个分类过程，其实naivebayes第二层结点就是一些分类，从第一层进行的动作就是将数据分到某一个类中，根据上面的理论可以很容易写出上图的联合概率密度，然后再计算第二层given第一层结点的条件概率密度，选择最大的即可进行分类。


## 参考链接: 
[贝叶斯决策论](http://www.cnblogs.com/elaron/archive/2012/10/29/2745010.html)


<br>

转载请注明:[Artemis的博客]([https://BlasphemyAngels.github.io)--> [点此看原文
](https://blasphemyangels.github.io/2017/03/bayes)
